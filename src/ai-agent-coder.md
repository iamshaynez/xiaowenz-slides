---
marp: true
theme: uncover
class:
  - invert
  - lead
header: 'AI Code Agent 工具培训'
footer: '© 2025 Google - 内部培训材料'
paginate: true
style: |
  section {
    font-size: 150%;
  }
---

# **AI Code Agent 工具培训**

从核心原理到大型工程实践

---

## **培训议程**

1.  **AI 的“大脑”**: 揭秘大型语言模型 (LLM)
2.  **从自动化到自主**: AI Agent 与传统 Workflow 的区别
3.  **“魔法”的边界**: AI Code Agent 的局限性与根源
4.  **核心开发实践**: 在日常工作中发挥 AI 最大效能
5.  **大型工程实践**: 在复杂项目中驾驭 AI
6.  **总结与 Q&A**

---

## **第一部分: AI 的“大脑”**
### 揭秘大型语言模型 (Large Language Model)

---

### **什么是大型语言模型 (LLM)?**

简单来说，可以把它想象成一个**超级增强版的代码自动补全**工具。

-   **不是一个数据库**: 它不“存储”代码，而是学习代码中的**模式和关系**。
-   **是一个概率模型**: 当你给它一段输入时，它会预测最有可能的下一个词（或代码 token）。
-   **“大型”的含义**:
    * **海量参数**: 数十亿甚至上万亿的参数，像大脑中的神经元连接。
    * **海量数据**: 在包括互联网、书籍和海量公开代码在内的庞大数据集上进行训练。

> **核心心智模型**: LLM 是一个基于概率的**序列补全引擎**。

---

### **LLM 如何“思考”？- Transformer 架构**

所有现代 LLM 的核心都是 **Transformer** 架构。其关键机制是 **“自注意力机制” (Self-Attention Mechanism)**。

**传统模型**: 顺序处理文本，容易忘记长距离的依赖关系。
**Transformer**:
-   **并行处理**: 同时处理输入的所有部分。
-   **注意力机制**: 动态计算输入中每个词与其他词的“相关性分数”，从而在生成下一个词时，能够“关注”到最相关的上下文信息，无论它们在输入中的距离有多远。

> 对开发者而言，这意味着模型能更好地理解代码中的长距离依赖，例如一个在文件开头定义的函数，在文件末尾被调用。

---

### **LLM 是如何“炼成”的？通用 vs. 代码模型**

虽然都基于 LLM，但通才（如 ChatGPT）和专才（Coder 模型）的训练过程侧重点不同。

| 训练阶段 | **通用 LLM (Generalist)** | **代码 LLM (Specialist)** |
| :--- | :--- | :--- |
| **预训练** | **数据**: 综合性数据 (网页、书籍、代码) <br> **目标**: 学习广泛的语言和世界知识。 | **数据**: **以代码为中心** (GitHub、StackOverflow) <br> **目标**: 深度学习编程语言的语法、结构和常见模式。 |
| **监督微调 (SFT)** | **数据**: 广泛的“指令-回答”对。 <br> **目标**: 学会遵循各种人类指令。 | **数据**: 高质量的“**编程问题-代码答案**”对。 <br> **目标**: 精通将自然语言需求翻译为功能性代码。 |
| **强化学习 (RLHF)** | **反馈**: 人类偏好 (有用、无害、诚实)。 <br> **目标**: 生成更符合人类价值观的回答。 | **反馈**: **功能性信号** (单元测试通过、编译成功、性能) + 人类偏好。<br> **目标**: 生成**正确、高效且可执行**的代码。 |


---

## **第二部分: 从自动化到自主**
### AI Agent 与传统 Workflow 的区别

---

### **AI Agent vs. Workflow: 核心区别**

| 特性 | **传统 Workflow/脚本** | **AI Agent** |
| :--- | :--- | :--- |
| **自主性** | 低 - 严格遵循预定义步骤 | 高 - 能根据目标自主规划和执行步骤 |
| **决策能力** | 无 - 依赖 `if-else` 等硬编码逻辑 | 强 - 能基于观察进行推理和动态决策 |
| **适应性** | 弱 - 遇到意外情况会失败或停止 | 强 - 能处理错误、适应变化、甚至自我修正 |
| **工作模式** | **命令式** (告诉它*如何*做) | **声明式** (告诉它*做什么*) |

> **举例**:
> - **Workflow**: `git add . -> git commit -m "msg" -> git push` (固定步骤)
> - **Agent**: 目标: "将当前更改推送到远程仓库"。Agent 会自己决定是否需要 `add`, `commit`，并处理可能出现的合并冲突。

---

## **第三部分: “魔法”的边界**
### AI Code Agent 的局限性与根源

---

### **局限性的根源: 概率模型的“天花板”**

AI Code Agent 的所有局限性，几乎都源于其核心——LLM——的**生成式和概率性本质**。

-   **它不理解“真理”**: 模型不知道什么是绝对正确的代码，只知道什么是**统计上最可能**的代码。它是在做“模式匹配”和“概率预测”，而不是“逻辑推理”。
-   **知识被“冻结”**: 模型的知识截止于其训练数据的最后日期。它不知道新的库版本、安全漏洞或 API 变更。
-   **上下文窗口有限**: 模型一次能“看到”的信息量是有限的。它无法像人类一样通览整个项目的宏观架构。

---

### **常见陷阱 1: 代码“幻觉” (Hallucination)**

-   **现象**: 生成不存在的函数、API、参数，或者用一种看似合理但完全错误的方式组合代码。
-   **原因**: 当模型在其训练数据中找不到强烈的模式匹配时，它会基于概率进行“创造”。这种创造不受事实约束，是**模式匹配成功，但与现实脱节**的结果。

### **常见陷阱 2: 上下文盲点 (Context Blindness)**

-   **现象**: 提出破坏项目架构的建议；引入不一致的编码风格；忽略关键的业务逻辑。
-   **原因**: **有限的上下文窗口**使其无法获得完整的全局视野。它就像一个“白痴天才”，能做好局部任务，但缺乏对全局的真正理解。

---

## **第四部分: 核心开发实践**
### 在日常工作中发挥 AI 最大效能

---

### **黄金法则: 你是机长，不是乘客**

**永远不要盲目信任 AI 生成的代码。**

-   **把它当作一个初级开发者**: 它能快速完成任务，但需要你的指导、审查和修正。
-   **审查每一行关键代码**: 特别是涉及安全、性能和核心业务逻辑的部分。
-   **最终责任在你**: 代码合并入主干前，你必须完全理解它的工作原理和潜在影响。

> **将 AI Agent 视为一个强大的生产力工具，而不是一个可以替代你思考的专家。**

---

### **打造完美的提示 (Prompt)**

Garbage In, Garbage Out. 提示的质量直接决定输出的质量。

-   **明确角色 (Role)**: "你现在是一个资深的 Go 开发者..."
-   **提供上下文 (Context)**: 粘贴相关的代码片段、错误信息、API 定义。**这是最重要的一步。**
-   **清晰的任务 (Task)**: "重构下面的函数..."
-   **定义输出格式 (Format)**: "...使用 markdown 代码块返回完整的函数代码。"
-   **设定约束 (Constraints)**: "...不要使用第三方库，确保代码符合 PEP8 规范。"

> **一个好的提示 = 角色 + 上下文 + 任务 + 格式 + 约束**

---

## **第五部分: 大型工程实践**
### 在复杂项目中驾驭 AI

---

### **大型项目的核心挑战**

在拥有数百万行代码、数百个模块的复杂项目中，之前的核心局限被急剧放大：

1.  **上下文迷失 (Context Blindness)**:
    * Agent 的小“上下文窗口”就像一个手电筒，在巨大的仓库里，它只能照亮一小片区域，完全看不到整体布局。
    * 盲目地给它大量文件，只会增加噪音，导致更严重的幻觉。

2.  **规范漂移 (Standard Drift)**:
    * Agent 倾向于使用其通用训练数据中的“大众化”编码风格，而不是你项目特有的、经过多年沉淀的工程规范。
    * 这会导致新生成的代码风格不一，难以维护，成为技术债。

---

### **实践一: 喂给 AI 精准的上下文 (Intelligent Context)**

目标：用最小的上下文，为 AI 提供完成任务所需的**所有必要信息**。

**解决方案**: **代码检索增强生成 (Retrieval-Augmented Generation for Code)**

```mermaid
graph TD
    subgraph "1. 离线索引 (Indexing)"
        A[项目代码库] -->|切分为逻辑块| B(代码块) -->|生成向量嵌入| C(向量数据库<br><i>Code Knowledge Base</i>)
    end
    subgraph "2. 实时检索 (Retrieval)"
        D[用户提示<br>"如何获取用户信息?"] --> E{智能检索模块}
        C --> E
    end
    subgraph "3. 增强与生成 (Augmentation & Generation)"
        F[相关代码片段1]
        G[相关代码片段2]
        E --> F
        E --> G
        H(LLM)
        D --> H
        F --> H
        G --> H
        H --> I[精准的代码答案]
    end
```
**核心思想**: 将你的问题（提示）和最相关的现有代码片段**一起**注入到 LLM 的上下文中。

---

### **实践二: 用工程规范约束 AI (Enforcing Standards)**

目标：让 AI 生成的代码，看起来就像是团队里最资深的工程师亲手写的。

**解决方案**: 创建一个 **`guidelines.md`** 文件，作为 AI 的“行为准则”。内容可以通过 agent 工具注入「全局」，「项目」，「模块」等不同的 scope。

-   **它是一个“契约”**: 你在这里定义了项目代码的规范，AI Agent 必须遵守。
-   **它是“活”的文档**: 随着项目演进，你可以随时更新这个文件。
-   **它能被 AI 理解**: 用自然语言和代码示例编写，非常适合 LLM 读取。
-   **自动化应用**: 免去了在每个提示中重复说明规范的麻烦。

---

### **`project_guide` 里应该写什么？**

#### **0. 工具工程设置**（如提示词语言，文档语言等，工具级别）
#### **1. 项目功能高阶描述和功能目标**（项目级别）
#### **2. 工程结构和对应代码逻辑规范**（项目级别）
#### **3. 模块功能描述和领域关键逻辑**（模块级别）
#### **4. 其他需要避免的 Don'ts**(按需)

---

### **一些思考**

- AI Agent 不会替代开发者，但会放大开发者的差距。
- 开发范式会发生改变，会有显著更多的时间：思考，描述， Review 和重构。
- 底层知识会比过去更重要。



